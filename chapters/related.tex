%TODO
\augusto{The goal is to reduce security related works , increase architecture focused ones}


%SOC
%\soc~devices have a number of features which distinguish them from other traditional electronic solutions. Their dedicated nature allows the adoption of more intrusive protection, while posing challenging energy and performance requirements. Unfortunately, traditional security solutions based on typical cryptographic mechanisms (e.g. bus encryption)  can have a significant impact in device cost, energy efficiency and performance. One way to go around that is to consider approaches which enable a deep integration of device hardware-intrinsic features and program execution, as those offered by \pufs.


Qualitative analyses of \pufs~have already been done in the literature~\cite{Katzenbeisser2012} motivated by several applications such as cryptographic key generation~\cite{Suh2007, Bhargava2014} and true random number generation~\cite{Leest2012, Herrewege2013}. Unlike those works, which aim at evaluating the quality of a standalone \puf-inspired mechanism, this work focus on proposing and analyzing a \puf-based micro-architecture mechanism to enable secure code execution. %\new{On big conundrum on using \pufs~is how to prevent unintended bit-flips on responses used to compound the cryptographic key. An approach to deal with that is to use post-processing schemes like Fuzzy Extractors \cite{}. Despite Fuzzy Extractors be a simple and known circuits, they the weakest spot on the architecture and can leak the cryptographic key through side channel attacks. }

Most of the preliminary work on secure code execution aimed at keeping instructions and data secure from scrutiny, by using mechanisms like bus encryption. In~\cite{Elbaz2005}, Elbaz \etal~performed a comprehensive survey of bus encryption, where they describe many possible ways of using cryptographic algorithms in \soc~architectures, so as to ensure that no malicious instruction\slash{}data would be executed by the CPU. The major shortcoming of these solutions is the usage of on-chip secret key storage in non-volatile memories which enable off-line key recovery attacks~\cite{towardshardwaresecurity2010}.

AEGIS, the secure processor proposed by Suh \etal~in~\cite{Suh2005}, employs \pufs~as a cryptography primitive to uniquely authenticate code and data in order to prevent both software and physical attacks. They present a toolchain for developing secure software for their architecture which includes a secure operating system to manage different levels of memory protection. Although the presented toolchain does not require modifications in the processor architecture, it demands extensive changes in the \soc~architecture, in addition to changes in the compiler and operating system. Moreover, AEGIS \emph{does not} ensure full-time security from power-on to power-off; i.e. the system runs unprotected until the security kernel loads the system. In addition, physical attacks were neither evaluated nor simulated. Different circuits used in AEGIS, like \pufs~and post-processing schemes for key extraction such as Fuzzy Extractors, have been successfully attacked with side-channel \cite{Merli2011,Tajik2016:Photonic} and semi-invasive attacks \cite{Tajik2015:LaserAttack}. While semi-invasive attacks are hard to repeal, side-channel attacks have few known countermeasures \cite{Merli2013:Masking} that can be easily adopted.


%A fine list of works in the literature has influenced this work. Their weaknesses and strengths, targeted systems, and construction helped us to make design choices to implement a proof of concept of \cshia. 
%Security 
%In 2003, Yang, Zhang, and Gao \cite{Yang2003:XOM} proposed an improved version of \xom, an architecture for digital copyright protection. The architecture provides authenticity through a pairwise private\slash{}public key. Every instance of a \xom~architecture has a unique private key. Secrecy is provided by encrypting software using specific symmetric keys chosen by the software vendor. These keys are encrypted using \xom's public key and therefore only the instance that has the correspondent private key will be able to execute the software. \xom~provides integrity protection by hashing memory blocks, but it only prevents spoofing and splicing. Replay attacks are left uncovered. The differential of \xom~is to isolate programs in compartments, which have their own tags and keys. Due to this isolation, new instructions had to be added to the processor in order to relax constraints of architecture. For example, to enable sharing data between isolated programs. From the point of view of targeted market, \xom~is suitable for very high end embedded systems or above since they simulated their architecture using a processor capable of out-of-order execution and \xom's performance highly depends on the existence of second-level cache (\ltwo) and its size. Finally, area overhead is not estimated, implementation is through simulation, and the averaged performance slowdown is 16.76\% on the tested benchmarks, however, they were able to reduce this slowdown to 1.28\% implementing an additional cache memory. 

%The first architecture that proposed to use \pufs~for key generation was \aegis, the work presented by Suh \etal~in \cite{Suh2005:AEGISImplementation}. \aegis~is a tamper-resistant and tamper-evident architecture. Meaning that it hinders tampering threats, but the system still indicates if an attacker successfully overpasses the security features. \aegis~is a complete solution in which not only new instructions are provided, but also system calls, security modes, and different divisions of memory into new regions. It can securely run even under an untrusted operating system. \aegis~provides a \mt~to prevent replay attacks and uses a small cache to store nodes and reduce performance penalties. All this security comes with downsides such as an almost 100\% area increase in comparison to the processor baseline, and the modification of the entire toolchain: compilers, operating systems, and even programs. Due to the complexity of the architecture, targeted systems are preferable high-end embedded systems or above. Although the authors are not very clear about overall performance penalties of the architecture, when they used their full protection mode and an architecture configuration consisting in 32 KB instruction\slash{}data cache and 16 KB \mt~cache, the worst benchmark performance overhead was 3.3\%. However, when the architecture configuration is 4 KB instruction\slash{}data cache and 2 KB \mt~cache, the same benchmark has a performance overhead of 73.1\%.

%Following \aegis~in 2005, Then SecBus 2009
%Liu 2013



%Rogers, Milenković, and Milenković presented in 2007 a secure architecture \cite{Rogers2007:LowOverhead}. Different from the previous works described above, they truly focused on embedded system since they assume that processors would not have second-level cache memory (\ltwo), but would present a separated \lone~into data and instruction memories. Their architecture provides integrity and secrecy for memory blocks of instructions, and data integrity is not discussed. The architecture uses virtual address to compound encrypted blocks, in order to thwart splicing attacks, they came up with a interesting solution of encrypting an unique \puf-generated (or thermal-noise generated) key together with the program this key authenticated. Thus, when two programs present a collision between virtual addresses, an attacker will not be able to switch programs because their key will be different. Although their architecture was only simulated, they estimated a power consumption overhead over the baseline system. Setting up a simulation of an ARM processor with small instruction \lone~cache of 1 KB resulted in a power consumption overhead as high as twice the baseline's value. In terms of performance penalties for the tested benchmarks, the results also were very detrimental for a small instruction \lone, achieving an overhead of 2 times greater than baseline's performance, and becoming negligible for a 8 KB instruction cache in the best scenario. At last, for a standard memory block of 256 bits, their storage overhead reached 50\% of the main memory, which is high. 

In 2009, Vaslin \etal~proposed a security approach for off-chip memory in embedded microprocessors \cite{Vaslin2009:OTP}. Vaslin \etal~used the One-Time-Pad (\otp) scheme to provide integrity and secrecy. Their architecture encrypts a timestamp, the memory address and a padding value using \aes. Then, this encrypted content is combined with the cache line. Because they used memory address and timestamp, relocation and replay attacks are thwarted. However, to inhibit spoofing attacks, memory blocks need tags and Vaslin \etal~proposed using \crc32. One critical point is that their architecture not only needs an internal timestamp memory but also a \crc32 memory. That led to an internal memory of at least 18.8\% of the size of main memory. Nonetheless, Vaslin \etal's architecture was able to achieve a worst case performance impact of 10\% in the tested benchmarks. However, the area overhead in the \fpga~tested almost tripled.

%\fedtic, the 2010 work of Hong and Guo \cite{Hong2010:FEDTIC}, is an architecture for integrity verification and secrecy for embedded systems. Their main contribution is a unique engine that uses one \aes~hardware instance for encryption, decryption, and tagging of cache lines. As in \cite{Vaslin2009:OTP}, a stamp is generated for each memory block write back, which prevents replay attacks. However, instead of a one-time-pad scheme, Hong and Guo used \aes~in output feedback mode which allowed them to use shifted encrypted blocks to compose a tag. In terms of achievements, for a 512 bit cache lines, their external memory overhead was less than 7\% and for the tested benchmarks a maximum internal memory for timestamps needed was 5 KB. We should notice that this internal memory is not a cache and thus will increase with the program size. The average performance penalty was 7.6\% and the maximum 30.72\%. Their evaluation used a combination of simulation and \fpga~implementation.

Bobade and Mankar presented in \cite{Bobade2015:SecurityFPGA} a secure architecture for embedded system. Their architecture provides integrity and secrecy through an Elliptic Curve Cryptographic engine. The main difference regarding the others architectures presented here is that they use the timestamps as private keys. Thus, cache lines are encapsulated with their address and time stamp (for integrity verification purpose), and then encrypted with the public key to be stored in external memory. As the timestamps are stored in an internal memory, the decryption can be done with reprocessing the pair private\slash{}public key and the integrity is ensured by the correct decryption of the triad encapsulated: data, address, and time stamp. Although Bobade and Mankar synthesized their architecture for a {\fpga}S, they only simulated the architecture and did not use any benchmark. Nonetheless, they computed the overhead of slices and \luts~over their baseline processor, which was over 76\%. Memory overhead was 25\%. In addition, they estimated power increment over baseline. Despite the dynamic power more than doubled in all processor's frequency simulated, the static was kept stable.

Recently, Sepulveda, Wilgerodt, and Pehl in \cite{Sepulveda2018:CSHIA} proposed a Multi-Processors System-on-Chip that provides memory integrity and authenticity through \pufs. The proposed architecture innovates by targeting multi-processors. They also used \siphash~to provide memory blocks integrity tags to protect against all three major threats we have discussed before. One key difference in their replay attack solution is that they use session tokens instead of timestamps. While that is an innovative way, it may not be sufficient to protect against replay attacks, since tokens are updated during idle periods and booting time. Thus, in a long period of execution, in which a specific memory block can be written back multiple times to memory, an attacker might mount a replay attack. One interesting point is that Sepulveda \etal argue that \cshia~needs deep modifications in \soc~and \cpu. However, we believed that this work demonstrates that only minor modification are needed and they are all transparent to the core and does not affect how it works. It is also important to notice that the authors used a similar Code-offset Fuzzy Extractor \cshia~had originally employed, which, as discussed in the previous section, is less secure than the one used in \cshia~in terms of entropy reduction of the key. Finally, they estimated area and power of the components of their architecture, and did performance evaluation which, by computing an average degradation, was 5.6\% on the tested benchmarks.

Table \ref{tab:related-work} presents a summary of advantages and drawbacks of \cshia~and related works. A fair comparison of performance among the works is quite hard to be performed, due to a variety of benchmarks, baseline cores, choice of platforms, etc. However, a qualitative analysis over design choices can still be done as discussed in section \ref{chap:cshia_architecture}. For instance, \pufs~have been constantly claimed to be a better solution for key generation than storing on-chip key. In that regard, \cshia~is more advantageous than those that did not use them. All the mentioned related works have a higher abstraction level, in this work we disclose the implementation details  and design tradoffs of \cshia. 

%security related 
%Moreover, we carefully analyzed major threats presented in the literature in order to propose a secure employment of a \puf-based key. Because embedded system applications can have a very specific nature, our concern since the beginning was to propose a flexible architecture, which is characterized by its additional bus for the \ptagmem~and the choice between timestamps or \mt~as replay attack solution. Thus, although we were not able to precisely estimate power and area, we believe that we presented a solid solution for the security of embedded systems. 





%\begin{sidewaystable}
\begin{table*}[!b]
	\center
	\caption{Summary of Related Works in comparison with \cshia.}
	\label{tab:related-work}
	\footnotesize
	\begin{tabular}{cp{1in}p{2in}p{2in}}
	%\resizebox{\textwidth}{!}{\begin{tabular}{cccc}

		\hline
			Work & Target Architecture & Advantages & Drawbacks \\	
		\hline
		%\hline
		%	\xom & High-End embedded systems and above & Program isolation & Does not provide protection against replay attacks. \\
		\hline
			\aegis\cite{Suh2005} & High-End embedded systems and above & A complete solution & Integration with standard products can be difficult due to modification imposed to the whole toolchain. \\
		%\hline
		%	\cite{Rogers2007:LowOverhead} & Embedded Systems & Program Isolation & High memory overhead. \\
		\hline
			\cite{Vaslin2009:OTP} & Embedded Systems & Uses \aes~in \otp~mode combined with \crc32 to provide integrity with low on-chip memory overhead. & High area overhead in a \fpga~implementation. \\
		%\hline
		%	\fedtic & Embedded Systems & Uses one \aes~component to encryption, decryption and authentication & Can impose large on-chip non-volatile memory. \\
		\hline
			\cite{Bobade2015:SecurityFPGA} & Embedded Systems & Security is based on public-key cryptography. & No performance evaluation.\\
		\hline
			\cite{Sepulveda2018:CSHIA} & MP\soc & First \puf~based secure architecture for multiple cores. & Does not estimate area and power increment in regard to the baseline system.\\
		\hline
			\cshia & Embedded Systems & Design Flexibility. & Does not provide concrete estimate of area and power. \\
		\hline
	\end{tabular}
	%}
%	\vspace*{-12pt}
%\end{sidewaystable}
\end{table*}